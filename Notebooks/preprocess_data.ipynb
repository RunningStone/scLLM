{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From raw data to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a vocab list\n",
    "# this related with the gene2vec model\n",
    "#----> pre-trained part\n",
    "vocab_loc = \"/Path/to/pre_trained/scBERT/vocab_gene2vec_16906.pkl\"\n",
    "#----> data part\n",
    "csv_loc = \"/Path/to/allMCF10data_batches_labelled_with_pseudotimes_normalised.csv\"\n",
    "adata_loc = \"Path/to/allMCF.h5ad\"\n",
    "\n",
    "import pickle\n",
    "with open(vocab_loc, \"rb\") as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init preprocessor\n",
    "from scLLM.Dataset.preprocessor import Preprocessor\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT\n",
    "dataset_para = Dataset_para(gene_vocab=vocab,\n",
    "                            filter_gene_by_counts=False,\n",
    "                            filter_cell_by_counts=200,\n",
    "                            log1p=True,\n",
    "                            log1p_base=2,\n",
    "                            )\n",
    "\n",
    "preprocess = Preprocessor(dataset_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data with csv file that you want to preprocess\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_loc)\n",
    "\n",
    "# gene_name_mask: gene name mask if this colume in csv file should be included, then\n",
    "#                            we set this gene name with True\n",
    "gene_name_mask = [True if i>=2 and i<2044 else False for i in range(len(list(df.keys())))]\n",
    "# sample_id_idx: a index in a csv file that can use to sample items \n",
    "sample_id_idx = \"Row.names\"\n",
    "# sample_mask: sample mask if this row in csv file should be included, then\n",
    "sample_mask = [True for i in range(df.shape[0])] # use all cases\n",
    "# obs_name_mask: label name in csv file.if this colume include a label, set ture\n",
    "obs_name_mask = [True if i==len(list(df.keys()))-1 else False for i in range(len(list(df.keys())))]\n",
    "\n",
    "preprocess.from_csv(\n",
    "    csv_loc = csv_loc,\n",
    "    gene_name_mask = gene_name_mask,\n",
    "    sample_id_idx = sample_id_idx,\n",
    "    sample_mask = sample_mask,\n",
    "    obs_name_mask=obs_name_mask,\n",
    "    df=df# optional\n",
    ")\n",
    "preprocess.run()\n",
    "preprocess.save_adata(adata_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.load_adata(adata_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess.to_data(data_type=\"log1p\")\n",
    "label,class_weight = preprocess.to_label(\n",
    "                          label_key=\"pseudotimes\",\n",
    "                          binarize=True,\n",
    "                          bin_nb=20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tr,idx_val = next(iter(sss.split(data, label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, label_train = data[idx_tr], label[idx_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape,label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scLLM.Dataset.dataset import SCDataset\n",
    "train_dataset = SCDataset(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = preprocess.to_dataloader(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Histo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d54c460629d4e98d9a88def0a4b8f729ffa99ca7bfc826c2a753ee2b4ef8936"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
